<!DOCTYPE html>

<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="description" content="David Shatwell's personal webpage">
    <meta name="keywords" content="David Shatwell">
    <meta name="author" content="David Shatwell">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <title>David Shatwell</title>

    <link rel="icon" href="images/david_shatwell_small.png">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" integrity="sha384-zCbKRCUGaJDkqS1kPbPd7TveP5iyJE0EjAuZQTgFLD2ylzuqKfdKlfG/eSrtxUkn" crossorigin="anonymous">
    <link rel="stylesheet" href="css/styles.css">
</head>


<body>

    <nav class="navbar navbar-dark bg-dark navbar-expand-sm">
        <div class="container">
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#Navbar">
                <span class="navbar-toggler-icon"></span>
            </button>

            <div class="collapse navbar-collapse" id="Navbar">
                <ul class="navbar-nav mr-auto">
                    <li class="nav-item"><a class="nav-link" href="#bio">Bio</a></li>
                    <li class="nav-item"><a class="nav-link" href="#papers">Papers</a></li>
                    <li class="nav-item"><a class="nav-link" href="#projects">Projects</a></li>
                    <li class="nav-item"><a class="nav-link" href="https://github.com/dshatwell23" target="_blank">GitHub</a></li>
                    <li class="nav-item"><a class="nav-link" href="documents/CV_DavidShatwell_20251022.pdf" target="_blank">CV</a></li>
                    <li class="nav-item"><a class="nav-link" href="https://drive.google.com/file/d/1zt5OpxPC8w0D_sRE_zHgwTsRExBRHs64/view?usp=share_link" target="_blank">GRE</a></li>
                    <li class="nav-item"><a class="nav-link" href="https://drive.google.com/file/d/1WZnjf8Ah3io-9OVUNMhuRxgy0kS_bKLI/view?usp=share_link" target="_blank">TOEFL</a></li>
                </ul>
            </div>

        </div>
    </nav>

    <div class="container">
        
        <!-- <div class="row toprow">
            <div class="image-column">
                <img class="bio-image" src="images/david_shatwell_medium_no_bg.png" alt="david-shatwell">
            </div>
            <div class="name-column">
                <h1>David Shatwell</h1>
                <p>
                    Researcher at <a href="http://www.hochschildmining.com/en/home">Hochschild Mining</a>
                    <br>
                    R&D Department
                    <br>
                    Email: <a href="mailto:dshatwell23@gmail.com">dshatwell23&#64;gmail.com</a>
                </p>
                <p>Research interests: Computer Vision, Machine Learning</p>
            </div>
        </div> -->

        <div class="row row-content">
            <div class="col-12 col-sm-5 d-flex justify-content-center">
                <img class="bio-image" src="images/david_shatwell_medium_no_bg.png" alt="david-shatwell">
            </div>
            <div class="col-12 col-sm-7 p-0 d-flex flex-column justify-content-center">
                <h1>David G. Shatwell</h1>
                <p>
                    PhD student at Center for Research in Computer Vision
                    <br>
                    University of Central Florida
                    <br>
                    <!-- Email: <a href="mailto:dshatwell23@gmail.com">dshatwell23&#64;gmail.com</a> -->
                    Email: dshatwell23 [at] gmail (dot) com
                </p>
                <p>Research interests: Geo-Localization, 3D Vision, Multimodal Learning</p>
            </div>
        </div>

        <hr>
        
        <div class="row row-content">
            <h2 id="bio">Bio</h2>
            <p class="bio">I am a 3rd year PhD student working under Dr. Mubarak Shah at the Center for Research in Computer Vision (CRCV) at UCF. My current research focuses on geo-temporal image retrieval and 3D reconstruction. Previously, I was a researcher in the R&D department at <a href="http://www.hochschildmining.com/en/home" target="_blank">Hochschild Mining</a>, a gold and silver mining company operating in Peru. In Hochschild, I was responsible for the Ore Sorting Research Lab, where we focused on developing new mineral classification algorithms using computer vision and machine learning. Previously, I did an internship in the R&D department at the <a href="https://www.igp.gob.pe/observatorios/radio-observatorio-jicamarca/?page_id=6609" target="_blank">Jicamarca Radio Observatory</a>, working with FPGAs and microprocessors under the supervision of <a href="https://www.igp.gob.pe/observatorios/radio-observatorio-jicamarca/?page_id=9288" target="_blank">Joaquin Verastegui</a> and <a href="https://www.igp.gob.pe/observatorios/radio-observatorio-jicamarca/?page_id=9079" target="_blank">John Rojas</a>. I have also worked as a computer vision consultant in occupational health clinic <a href="https://wh.com.pe/" target="_blank">Work & Health</a>, developing projects using pose estimation and thermal imaging.</p>
            <p class="bio">I got my undergraduate degree from <a href="https://utec.edu.pe/en" target="_blank">UTEC</a> in Electrical Engineering and finished first of my class. Under the supervision of <a href="https://utec.edu.pe/en/faculty/victor-manuel-murray-herrera" target="_blank">Victor Murray</a>, I wrote my honors thesis on mineral classification using color and texture features of digital images. My thesis achieved the highest possible grade and won second place in the undergraduate thesis competition organized by UTEC. During my studies, I also worked as TA of the Digital Circuits Lab, designing, supervising, and grading lab projects with FPGAs.</p>
        </div>

        
        <div class="row row-content">

            <div class="col-12 col-sm-6 col-md-3">
                <div class="d-flex flex-column align-items-center">
                    <div class="logo-container">
                        <a href="https://www.crcv.ucf.edu/" target="_blank"><img src="images/ucf_logo.png" alt="utec-logo" class="logo"></a>
                    </div>
                    
                    <span class="logo-jobs-desc">University of Central Florida<br>2023-2028</span>
                </div>
            </div>
            
            
            <div class="col-12 col-sm-6 col-md-3">
                <div class="d-flex flex-column align-items-center">
                    <div class="logo-container">
                        <a href="https://utec.edu.pe/en" target="_blank"><img src="images/utec_logo.png" alt="utec-logo" class="logo"></a>
                    </div>
                    
                    <span class="logo-jobs-desc">University of Engineering and Technology - UTEC<br>2015-2020</span>
                </div>
            </div>

            <div class="col-12 col-sm-6 col-md-3">
                <div class="d-flex flex-column align-items-center">
                    <div class="logo-container">
                        <a href="https://www.igp.gob.pe/observatorios/radio-observatorio-jicamarca/?page_id=6609" target="_blank"><img src="images/roj_logo.png" alt="roj-logo" class="logo"></a>
                    </div>
                    <span class="logo-jobs-desc">Jicamarca Radio Observatory<br>Winter 2019</span>
                </div>
            </div>

            <div class="col-12 col-sm-6 col-md-3">
                <div class="d-flex flex-column align-items-center">
                    <div class="logo-container">
                        <a href="https://wh.com.pe/" target="_blank"><img src="images/wnh_logo.png" alt="wnh_logo" class="logo"></a>
                    </div>
                    <span class="logo-jobs-desc">Work & Health<br>2020-2021</span>
                </div>
            </div>

            <div class="col-12 col-sm-6 col-md-3">
                <div class="d-flex flex-column align-items-center">
                    <div class="logo-container">
                        <a href="http://www.hochschildmining.com/en/home" target="_blank"><img src="images/hoc_logo.png" alt="hoc_logo" class="logo"></a>
                    </div>
                    <span class="logo-jobs-desc">Hochschild Mining<br>2019-2022</span>
                </div>
            </div>

        </div>

        <!-- <div class="row">
            <table>
                <tr>
                    <td><a href="https://utec.edu.pe/en" target="_blank"><img src="images/utec_logo.png" alt="utec-logo" class="logo"></a></td>
                    <td><a href="https://www.igp.gob.pe/observatorios/radio-observatorio-jicamarca/?page_id=6609" target="_blank"><img src="images/roj_logo.png" alt="roj-logo" class="logo"></a></td>
                    <td><a href="https://wh.com.pe/" target="_blank"><img src="images/wnh_logo.png" alt="wnh_logo" class="logo"></a></td>
                    <td><a href="http://www.hochschildmining.com/en/home" target="_blank"><img src="images/hoc_logo.png" alt="hoc-logo" class="logo"></a></td>
                </tr>
                <tr>
                    <td>University of<br>Engineering and<br>Technology - UTEC<br>2015-2020</td>
                    <td>Jicamarca<br>Radio Observatory <br> Winter 2019</td>
                    <td>Work & Health <br> 2020-2021</td>
                    <td>Hochschild Mining <br> 2019-Present</td>
                </tr>
            </table>
        </div> -->









        <hr>
        <div class="row">
            <h2 id="projects">Papers</h2>

            <div class="project">
                <h3>GT-Loc: Unifying When and Where in Images Through a Joint Embedding Space</h3>
                <h4>International Conference on Computer Vision, ICCV 2025</h4>
                <h4 style="color: red;">Oral Presentation (top 0.6%)</h4>
                <h4 class="project">David Shatwell, Ishan Rajendrakumar Dave, Sirnam Swetha, Mubarak Shah</h4>
                <img src="images/gtloc_teaser.png" alt="teaser_gtloc" class="thumbnail">
                <p>Timestamp prediction aims to determine when an image was captured using only visual information, supporting applications such as metadata correction, retrieval, and digital forensics. In outdoor scenarios, hourly estimates rely on cues like brightness, hue, and shadow positioning, while seasonal changes and weather inform date estimation. However, these visual cues significantly depend on geographic context, closely linking timestamp prediction to geo-localization. To address this interdependence, we introduce GT-Loc, a novel retrieval-based method that jointly predicts the capture time (hour and month) and geo-location (GPS coordinates) of an image. Our approach employs separate encoders for images, time, and location, aligning their embeddings within a shared high-dimensional feature space. Recognizing the cyclical nature of time, instead of conventional contrastive learning with hard positives and negatives, we propose a temporal metric-learning objective providing soft targets by modeling pairwise time differences over a cyclical toroidal surface. We present new benchmarks demonstrating that our joint optimization surpasses previous time prediction methods, even those using the ground-truth geo-location as an input during inference. Additionally, our approach achieves competitive results on standard geo-localization tasks, and the unified embedding space facilitates compositional and text-based image retrieval.</p>
                <div>
                    <a href="https://davidshatwell.com/gtloc.github.io/" class="btn" target="_blank" role="button">
                        <button type="button" class="btn btn-primary btn-sm">Project Page</button>
                    </a>
                    <a href="https://arxiv.org/abs/2507.10473" class="btn" target="_blank" role="button">
                        <button type="button" class="btn btn-primary btn-sm">Arxiv</button>
                    </a>
                    <a href="https://iccv.thecvf.com/media/PosterPDFs/ICCV%202025/544.png?t=1759974999.7209623" class="btn" target="_blank" role="button">
                        <button type="button" class="btn btn-primary btn-sm">Poster</button>
                    </a>
                </div>
            </div>

            <div class="project">
                <h3>Real Time Ore Sorting Using Color and Texture Analysis</h3>
                <h4>International Journal of Mining Science and Technology, 2023</h4>
                <h4 class="project">David Shatwell, Victor Murray, Augusto Barton</h4>
                <img src="images/poster_ore_sorting_color_texture.png" alt="poster_ore_sorting_color_texture" class="thumbnail">
                <p>Sensor-based ore sorting is a technology used to classify high-grade mineralized rocks from low-grade waste rocks to reduce operation costs. Many ore sorting algorithms using color images have been proposed in the past, but few validate their results using mineral grades or optimize the algorithms to classify rocks in real-time. This paper presents an ore sorting algorithm based on image processing and machine learning that is able to classify rocks from a gold and silver mine based on their grade. The algorithm is composed of four main stages: (i) image segmentation and partition into sub-images, (ii) feature extraction us- ing color statistics, principal component analysis, and wavelet texture analysis, (iii) sub-image classification using neural networks, and (iv) a voting system to determine the overall class of the rock. The algorithm was trained using rocks that a geologist manually classified according to their mineral content and rocks analyzed in a geochemical laboratory to determine their gold and silver grades. The proposed method was compared with other commonly used classification algorithms such as convolutional neural networks and support vector machines. The results produced a Matthews correlation coefficient of 0.961 points and a processing time under 44 ms, promising for real-time ore sorting applications.</p>
                <div>
                    <a href="https://www.sciencedirect.com/science/article/pii/S2095268623000502" class="btn" target="_blank" role="button">
                        <button type="button" class="btn btn-primary btn-sm">Paper</button>
                    </a>
                </div>
            </div>




        <hr>
        <div class="row">
            <h2 id="projects">Projects</h2>

            <div class="project">
                <h3>Control Software for Color and 3D Profiling Cameras</h3>
                <h4 class="project">Hugo Negreyros, David Shatwell</h4>
                <img src="images/poster_camera_control.png" alt="poster_camera_control" class="thumbnail">
                <p>Line-scan cameras are cameras that, unlike area-scan cameras, acquire a single row instead of a full 2D image. This type of cameras has several advantages over the traditional area-scan technology. In particular, they can capture images of objects moving at very high speeds with very little motion blur. In order to form 2D images, line-scan cameras are usually used on applications where a conveyor belt moves objects at a constant speed. In this project, we implemented a program used to synchronize and control two cameras at the same time. The first camera is a color camera (Teledyne Dalsa Spyder 3 GigE), while the second one is a 3D profiling camera (Automation Technology C2-2040 GigE), both of which are controlled using Gigabit Ethernet. We use the cameras to acquire color images, height profiles, and laser reflection/dispersion images, which are useful for identifying material properties in sorting applications.</p>
                <!-- <div class="btn-group" role="group">
                    <p>
                        <a href="https://github.com/dshatwell23/linescan-cameras-control" class="btn" target="_blank" role="button">Code</a>
                    </p>
                </div> -->
                <div>
                    <a href="https://github.com/dshatwell23/linescan-cameras-control" class="btn" target="_blank" role="button">
                        <button type="button" class="btn btn-primary btn-sm">Code</button>
                    </a>
                </div>
            </div>

            <div class="project">
                <h3>Ore Sorting using Color and Hyperspectral Imaging</h3>
                <h4 class="project">David Shatwell, Victor Murray, Augusto Barton</h4>
                <img src="images/poster_ore_sorting_color_hs.png" alt="poster_ore_sorting_color_hs" class="thumbnail">
                <p>Sensor-based ore sorting is a technology used to classify mineralized and waste rocks with the goal of reducing operating costs. In the past, several classification algorithms using color or hyperspectral images have been proposed, but few of them use both types of images in order to achieve a higher classification performance. This paper presents a new algorithm that combines the best color, texture, and hyperspectral features in a fully autonomous way using machine learning. The proposed algorithm was tested with rock particles extracted from an underground mine located in the peruvian Andes. All images were manually classified by an expert geologist and then were analyzed in a chemical laboratory in order to estimate their gold and silver grade. The results achieved with the proposed method were very promising, with a Matthews' correlation coefficient (MCC)  of 0.9787 and a potential increase in recovery of 1.4% compared to other commercial ore sorting solutions. <strong>This paper was selected as one of 25 finalists in the Technological Innovation category of the National Mining Contest. The results of the paper will be presented in the <a href="https://perumin.com/perumin35/public/en" target="_blank">PERUMIN 35</a> conference on September 28, 2022.</strong></p>
            </div>

            <div class="project">
                <h3>Classification of Satellite Images based on their Class of Terrain</h3>
                <h4 class="project">David Shatwell, Alejandro Weston, Oscar Ramos</h4>
                <img src="images/poster_satellite_image_classification.png" alt="satellite_image_classification", class="thumbnail">
                <p>Satellite image classification and analysis has many important applications in the real world, such as tracking deforestation and desertification levels, glacier movement, and even urban expansion. In this paper, we propose a satellite image analysis algorithm based on sub-image classification. The proposed algorithm can identify up to five different classes of terrain: city, sand, vegetation, mountain and water. In order to find the best possible image analysis algorithm, we trained and compared the classification performance of four common machine learning algorithms that require manual feature extraction and one deep learning algorithm with automatic feature extraction. All sub-images used to train and test the models were acquired from Google Earth at different heights. The models were tested using sub-images that come from the same images as the training set and also with sub-images that come from other images not used for training. After evaluating the performance of all models, the best one was selected for the task of satellite image analysis.</p>
                <!-- <div class="btn-group" role="group">
                    <p>
                        <a href="documents/shatwell2022classification.pdf" class="btn" target="_blank" role="button">Paper</a>
                        <a href="https://github.com/dshatwell23/satellite-image-classification" class="btn" target="_blank" role="button">Code</a>
                    </p>
                </div> -->
                <div>
                    <!-- <a href="documents/shatwell2022classification.pdf" class="btn" target="_blank" role="button">
                        <button type="button" class="btn btn-primary btn-sm">Paper</button>
                    </a> -->
                    <a href="https://github.com/dshatwell23/satellite-image-classification" class="btn" target="_blank" role="button">
                        <button type="button" class="btn btn-primary btn-sm">Code</button>
                    </a>
                </div>
            </div>

            <div class="project">
                <h3>Anthropometric Measurements Estimation using OpenPose Algorithm</h3>
                <h4 class="project">David Shatwell</h4>
                <img src="images/poster_anthropometric_measurements.png" alt="poster_anthropometric_measurements" class="thumbnail">
                <p>In occupational health clinics, doctors perform medical triage by measuring the vital signs of patients, as well as their anthropometric measurements, such as height and the circunference of the neck, thorax, abdomen and waist. This process is time consuming and can be automated to reduce patient waiting times. In this project, we propose an anthropometric measurement estimation algorithm using the OpenPose model developed by CMU Perceptual Computing Lab. The algorithm estimates the neck, thorax, abdomen and waist measurement projections of male patients using single frontal images. Future work will focus on developing regression models to estimate the circunference of the selected areas based on the frontal projections.</p>
                <!-- <div class="btn-group" role="group">
                    <p>
                        <a href="https://github.com/dshatwell23/anthropometric-measurements" class="btn" target="_blank" role="button">Code</a>
                    </p>
                </div> -->
                <div>
                    <a href="https://github.com/dshatwell23/anthropometric-measurements" class="btn" target="_blank" role="button">
                        <button type="button" class="btn btn-primary btn-sm">Code</button>
                    </a>
                </div>
            </div>

            <div class="project">
                <h3>Temperature Analysis on Different Parts of the Back of Patients Using Thermal Imaging and Pose Estimation</h3>
                <h4 class="project">David Shatwell</h4>
                <img src="images/poster_back_temperature_analysis.png" alt="poster_back_temperature_analysis", class="thumbnail">
                <p>This project, developed in partnership with a peruvian occupational health clinic, consists of an algorithm that computes temperature statistics of 10 different parts of the back of patients using thermal images and the OpenPose model, developed by the CMU Perceptual Computing Lab. The algorithm has three main stages. The first stage uses a color (RGB) image to find the location of several body parts of the patient. This keypoints are then used to define the 10 regions. Finally, we compute temperature statistics from each region. The proposed method could potentially be used by a health professional in the future to find lessions in the backs of patients.</p>
                <!-- <div class="btn-group" role="group">
                    <p>
                        <a href="https://github.com/dshatwell23/back-temperature-analysis" class="btn" target="_blank" role="button">Code</a>
                    </p>
                </div> -->
                <div>
                    <a href="https://github.com/dshatwell23/back-temperature-analysis" class="btn" target="_blank" role="button">
                        <button type="button" class="btn btn-primary btn-sm">Code</button>
                    </a>
                </div>
            </div>

            <div class="project">
                <h3>2-DOF PID Control of the Angular Position of an Industrial Plant Emulator</h3>
                <h4 class="project">David Shatwell, Frank Salazar, Arturo Rojas-Moreno,</h4>
                <img src="images/poster_2_dof_pid_contol.png" alt="poster_2_dof_pid_contol" class="thumbnail">
                <p>This paper employs a 2–DOF (2 Degrees of Freedom) PID (Proportional Integral Derivative) controller to control the angular position of the rotational load of an industrial plant emulator. The plant consists of a DC servo motor that is connected to a speed reducer with backlash, which in turn is connected to a rotational load through an elastic belt. The performance of the 2–DOF PID control system is compared with the performance of a PID control system. Experimental results demonstrate that the former control system performs better in the presence of multiple disturbances such as backlash, friction and vibration by decreasing the magnitude of the oscillations in the steady state.</p>
                <!-- <div class="btn-group" role="group">
                    <p>
                        <a href="https://ieeexplore.ieee.org/document/9220262" class="btn" target="_blank" role="button">Paper</a>
                        <a href="documents/shatwell2020two_slides.pdf" class="btn" target="_blank" role="button">Slides</a>
                        <a href="https://github.com/dshatwell23/2-dof-pid-control" class="btn" target="_blank" role="button">Code</a>
                    </p>
                </div> -->
                <div>
                    <a href="https://ieeexplore.ieee.org/document/9220262" class="btn" target="_blank" role="button">
                        <button type="button" class="btn btn-primary btn-sm">Paper</button>
                    </a>
                    <a href="documents/shatwell2020two_slides.pdf" class="btn" target="_blank" role="button">
                        <button type="button" class="btn btn-primary btn-sm">Slides</button>
                    </a>
                    <a href="https://github.com/dshatwell23/2-dof-pid-control" class="btn" target="_blank" role="button">
                        <button type="button" class="btn btn-primary btn-sm">Code</button>
                    </a>
                </div>
            </div>

            <div class="project">
                <h3>Data Transmission Through Gigabit Ethernet from a LVDS Interface Using a System On Chip (Single Board Computer + FPGA)</h3>
                <h4 class="project">David Shatwell, Joaquin Verastegui, John Rojas</h4>
                <img src="images/poster_lvds_to_ethernet.png" alt="poster_lvds_to_ethernet" class="thumbnail">
                <p>The objective of this project was to design and implement a system capable of transmitting data at high speeds from the JARS 2.0 radar to a remote computer through Gigabit Ethernet using a system on chip (SoC). The system has two main stages: (i) data acquisition from the LVDS interface and (ii) data transmission to the computer through a communication protocol. In order to acquire data from the LVDS interface, the FPGA was used to implement a system capable of multiplexing and copying the data to a memory shared with the processor. Then, a program running on the processor was used to read the data from the shared memory and send it to the PC with the UDP protocol.</p>
                <!-- <div class="btn-group" role="group">
                    <p>
                        <a href="documents/shatwell2019data_en.pdf" class="btn" target="_blank" role="button">Paper (EN)</a>
                        <a href="documents/shatwell2019data_es.pdf" class="btn" target="_blank" role="button">Paper (ES)</a>
                        <a href="https://github.com/dshatwell23/lvds-to-gige" class="btn" target="_blank" role="button">Code</a>
                    </p>
                </div> -->
                <div>
                    <a href="documents/shatwell2019data_en.pdf" class="btn" target="_blank" role="button">
                        <button type="button" class="btn btn-primary btn-sm">Paper (EN)</button>
                    </a>
                    <a href="documents/shatwell2019data_es.pdf" class="btn" target="_blank" role="button">
                        <button type="button" class="btn btn-primary btn-sm">Paper (ES)</button>
                    </a>
                    <a href="https://github.com/dshatwell23/lvds-to-gige" class="btn" target="_blank" role="button">
                        <button type="button" class="btn btn-primary btn-sm">Code</button>
                    </a>
                </div>
            </div>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha384-fQybjgWLrvvRgtW6bFlB7jaZrFsaBXjsOMm/tB9LTS58ONXgqbR9W8oWht/amnpF" crossorigin="anonymous"></script>
</body>
</html>